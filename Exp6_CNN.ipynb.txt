{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fIP-PQ6P4GVr"
      },
      "outputs": [],
      "source": [
        "#load packages and modules\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ybktYm4smK",
        "outputId": "4423f46d-6646-4032-92dd-9f9ad4e9e880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpYXJp0y5WQ-"
      },
      "outputs": [],
      "source": [
        "#preprocessing the data\n",
        "X_train =X_train .reshape(60000,784).astype('float32')\n",
        "X_valid =X_valid .reshape(10000,784).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4nKbe4G6xqK"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "X_train /=255\n",
        "X_valid /=255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2bhqHVI7pn7",
        "outputId": "84a218bf-ec1a-42b7-f441-2ed06ef73332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrqxCmv869hk"
      },
      "outputs": [],
      "source": [
        "#convert the labels to one hot representation.\n",
        "from keras import utils as np_utils\n",
        "n_classes=10\n",
        "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_classes)\n",
        "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v29GuNsh7my-",
        "outputId": "8a3c4be8-27a3-4c95-e825-3849cebcdfdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoUGssjR7whX"
      },
      "outputs": [],
      "source": [
        "#Defining the model\n",
        "model=Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMgBDIn_7-BN"
      },
      "outputs": [],
      "source": [
        "#Adding dense layer\n",
        "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad1nUITa8Qw1"
      },
      "outputs": [],
      "source": [
        "#Adding the final layer\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjtQIgRl8ed3",
        "outputId": "ccc41b36-636d-41f2-e340-e85253be70e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb8pK8Nh9cW0"
      },
      "outputs": [],
      "source": [
        "#compile the network\n",
        "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgQnYyYM94j7",
        "outputId": "eb6c7a12-59fb-4717-cad3-596f936fcb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0926 - accuracy: 0.1190\n",
            "Epoch 2/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.1322\n",
            "Epoch 3/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.1474\n",
            "Epoch 4/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.1656\n",
            "Epoch 5/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.1898\n",
            "Epoch 6/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.2166\n",
            "Epoch 7/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.2394\n",
            "Epoch 8/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.2605\n",
            "Epoch 9/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.2782\n",
            "Epoch 10/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.2926\n",
            "Epoch 11/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.3069\n",
            "Epoch 12/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.3165\n",
            "Epoch 13/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.3272\n",
            "Epoch 14/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.3371\n",
            "Epoch 15/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.3428\n",
            "Epoch 16/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.3525\n",
            "Epoch 17/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.3594\n",
            "Epoch 18/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.3690\n",
            "Epoch 19/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.3806\n",
            "Epoch 20/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.3979\n",
            "Epoch 21/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.4157\n",
            "Epoch 22/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.4402\n",
            "Epoch 23/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.4586\n",
            "Epoch 24/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.4770\n",
            "Epoch 25/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.4940\n",
            "Epoch 26/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.5030\n",
            "Epoch 27/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0818 - accuracy: 0.5118\n",
            "Epoch 28/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.5199\n",
            "Epoch 29/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.5247\n",
            "Epoch 30/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.5293\n",
            "Epoch 31/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0801 - accuracy: 0.5325\n",
            "Epoch 32/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.5365\n",
            "Epoch 33/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.5387\n",
            "Epoch 34/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.5418\n",
            "Epoch 35/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.5446\n",
            "Epoch 36/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.5481\n",
            "Epoch 37/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.5476\n",
            "Epoch 38/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.5527\n",
            "Epoch 39/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.5554\n",
            "Epoch 40/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.5586\n",
            "Epoch 41/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.5617\n",
            "Epoch 42/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0749 - accuracy: 0.5641\n",
            "Epoch 43/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.5664\n",
            "Epoch 44/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.5701\n",
            "Epoch 45/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.5730\n",
            "Epoch 46/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.5756\n",
            "Epoch 47/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.5784\n",
            "Epoch 48/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.5826\n",
            "Epoch 49/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.5858\n",
            "Epoch 50/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.5905\n",
            "Epoch 51/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.5929\n",
            "Epoch 52/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.5964\n",
            "Epoch 53/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.6001\n",
            "Epoch 54/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.6033\n",
            "Epoch 55/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.6064\n",
            "Epoch 56/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.6105\n",
            "Epoch 57/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.6144\n",
            "Epoch 58/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.6181\n",
            "Epoch 59/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.6213\n",
            "Epoch 60/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.6249\n",
            "Epoch 61/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.6288\n",
            "Epoch 62/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.6319\n",
            "Epoch 63/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.6351\n",
            "Epoch 64/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.6385\n",
            "Epoch 65/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.6421\n",
            "Epoch 66/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.6455\n",
            "Epoch 67/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.6490\n",
            "Epoch 68/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.6515\n",
            "Epoch 69/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.6541\n",
            "Epoch 70/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.6572\n",
            "Epoch 71/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.6599\n",
            "Epoch 72/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.6631\n",
            "Epoch 73/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.6660\n",
            "Epoch 74/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.6688\n",
            "Epoch 75/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.6716\n",
            "Epoch 76/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.6743\n",
            "Epoch 77/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.6771\n",
            "Epoch 78/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.6794\n",
            "Epoch 79/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.6827\n",
            "Epoch 80/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.6852\n",
            "Epoch 81/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0552 - accuracy: 0.6878\n",
            "Epoch 82/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.6913\n",
            "Epoch 83/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.6935\n",
            "Epoch 84/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.6967\n",
            "Epoch 85/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.6988\n",
            "Epoch 86/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.7022\n",
            "Epoch 87/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0527 - accuracy: 0.7048\n",
            "Epoch 88/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.7076\n",
            "Epoch 89/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.7100\n",
            "Epoch 90/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.7132\n",
            "Epoch 91/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.7162\n",
            "Epoch 92/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.7194\n",
            "Epoch 93/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.7223\n",
            "Epoch 94/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0500 - accuracy: 0.7246\n",
            "Epoch 95/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0496 - accuracy: 0.7272\n",
            "Epoch 96/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.7297\n",
            "Epoch 97/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.7330\n",
            "Epoch 98/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.7355\n",
            "Epoch 99/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.7375\n",
            "Epoch 100/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.7400\n",
            "Epoch 101/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.7422\n",
            "Epoch 102/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.7440\n",
            "Epoch 103/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0469 - accuracy: 0.7456\n",
            "Epoch 104/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0466 - accuracy: 0.7475\n",
            "Epoch 105/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.7494\n",
            "Epoch 106/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.7513\n",
            "Epoch 107/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.7529\n",
            "Epoch 108/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0453 - accuracy: 0.7549\n",
            "Epoch 109/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.7566\n",
            "Epoch 110/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0447 - accuracy: 0.7577\n",
            "Epoch 111/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.7593\n",
            "Epoch 112/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0441 - accuracy: 0.7611\n",
            "Epoch 113/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.7622\n",
            "Epoch 114/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0436 - accuracy: 0.7635\n",
            "Epoch 115/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.7651\n",
            "Epoch 116/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.7663\n",
            "Epoch 117/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.7674\n",
            "Epoch 118/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.7683\n",
            "Epoch 119/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0422 - accuracy: 0.7694\n",
            "Epoch 120/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0420 - accuracy: 0.7708\n",
            "Epoch 121/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0417 - accuracy: 0.7721\n",
            "Epoch 122/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.7734\n",
            "Epoch 123/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.7749\n",
            "Epoch 124/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.7763\n",
            "Epoch 125/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0407 - accuracy: 0.7777\n",
            "Epoch 126/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.7796\n",
            "Epoch 127/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.7809\n",
            "Epoch 128/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.7825\n",
            "Epoch 129/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.7839\n",
            "Epoch 130/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.7858\n",
            "Epoch 131/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0393 - accuracy: 0.7872\n",
            "Epoch 132/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.7890\n",
            "Epoch 133/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.7907\n",
            "Epoch 134/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.7924\n",
            "Epoch 135/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.7941\n",
            "Epoch 136/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0382 - accuracy: 0.7960\n",
            "Epoch 137/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.7978\n",
            "Epoch 138/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.7994\n",
            "Epoch 139/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.8011\n",
            "Epoch 140/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.8028\n",
            "Epoch 141/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0371 - accuracy: 0.8048\n",
            "Epoch 142/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.8069\n",
            "Epoch 143/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.8085\n",
            "Epoch 144/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.8101\n",
            "Epoch 145/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0363 - accuracy: 0.8116\n",
            "Epoch 146/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.8131\n",
            "Epoch 147/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.8145\n",
            "Epoch 148/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.8159\n",
            "Epoch 149/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.8176\n",
            "Epoch 150/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0354 - accuracy: 0.8188\n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rlSapyZ4QxG",
        "outputId": "bfc4d84a-c04c-405e-ee86-723f45198559"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression(random_state=0))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
        "X_train, X_valid, Y_train,Y_valid = train_test_split(X, Y, stratify=Y)\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rz2_y_PV4SK0",
        "outputId": "1c0e0030-43ec-4200-b224-e1b47a181dc6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = clf.predict(X_valid)\n",
        "cm = confusion_matrix(Y_valid, Y_pred)\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Exp6- CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZK4nl1uYqbUuxBg29yv0M"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}